# Hierarchical Architecture Search for AutoRL

Applying AutoML to reinforcement learning is a challenging problem that if solved, can lead to tremendous improvements in finding new neural architectures and optimizing them efficiently. Sample-Efficient Automated Deep Reinforcement Learning introduces an AutoRL framework that can meta-optimize arbitrary off-policy RL algorithms using population-based training. We introduce a new two-level hierarchical architecture search on top of vanilla SEARL in order to help the algorithm imitate the modularized design pattern commonly adopted in state-of-the-art neural architectures. By decomposing neural agents in an arrangement of cells, we are able to perform more varied types of mutations which either affect specific agents or specific neural patterns called cells.







